{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1> 물리학에서 세 번째로 어려운 문제를 꼽자면 새로운 발견 성과를 자축할 때 쓸 적당한 와인을 찾는 것이다. </h1>\n",
    "<h1> 4장의 와인 데이터를 읽어서 적당한 수의 입력 파라미터를 가지는 모델을 만들어라 </h1>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "wine_path = \"../data/winequality-white.csv\"\n",
    "wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=\";\",\n",
    "                         skiprows=1)\n",
    "\n",
    "wineq = torch.from_numpy(wineq_numpy)\n",
    "\n",
    "n_samples = wineq_numpy.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "wine_train = wineq[train_indices, :-1]\n",
    "wine_target_train = wineq[train_indices, -1]\n",
    "\n",
    "wine_val = wineq[val_indices, :-1]\n",
    "wine_target_val = wineq[val_indices, -1]\n",
    "\n",
    "wine_train = 0.1 * wine_train\n",
    "wine_val = 0.1 * wine_val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "seq_model = nn.Sequential(\n",
    "            nn.Linear(11, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, 1))\n",
    "\n",
    "optimizer = optim.SGD(seq_model.parameters(), lr=1e-4)\n",
    "\n",
    "def loss_fn(wine_train, wine_target):\n",
    "    squared_diffs = (wine_train - wine_target)**2\n",
    "    return squared_diffs.mean()\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, wine_train, wine_val, wine_target_train, wine_target_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        wine_train_out = model(wine_train)\n",
    "        loss_train = loss_fn(wine_train_out, wine_target_train)\n",
    "\n",
    "        wine_val_out = model(wine_val)\n",
    "        loss_val = loss_fn(wine_val_out, wine_target_val)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 1 or epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
    "                  f\" Validation loss {loss_val.item():.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 39.8454, Validation loss 39.8990\n",
      "Epoch 100, Training loss 0.9632, Validation loss 0.9995\n",
      "Epoch 200, Training loss 0.9441, Validation loss 0.9784\n",
      "Epoch 300, Training loss 0.9371, Validation loss 0.9714\n",
      "Epoch 400, Training loss 0.9305, Validation loss 0.9648\n",
      "Epoch 500, Training loss 0.9242, Validation loss 0.9586\n",
      "Epoch 600, Training loss 0.9182, Validation loss 0.9527\n",
      "Epoch 700, Training loss 0.9125, Validation loss 0.9471\n",
      "Epoch 800, Training loss 0.9072, Validation loss 0.9419\n",
      "Epoch 900, Training loss 0.9021, Validation loss 0.9369\n",
      "Epoch 1000, Training loss 0.8973, Validation loss 0.9322\n",
      "Epoch 1100, Training loss 0.8927, Validation loss 0.9277\n",
      "Epoch 1200, Training loss 0.8884, Validation loss 0.9234\n",
      "Epoch 1300, Training loss 0.8843, Validation loss 0.9194\n",
      "Epoch 1400, Training loss 0.8804, Validation loss 0.9156\n",
      "Epoch 1500, Training loss 0.8767, Validation loss 0.9120\n",
      "Epoch 1600, Training loss 0.8732, Validation loss 0.9086\n",
      "Epoch 1700, Training loss 0.8698, Validation loss 0.9054\n",
      "Epoch 1800, Training loss 0.8667, Validation loss 0.9024\n",
      "Epoch 1900, Training loss 0.8637, Validation loss 0.8995\n",
      "Epoch 2000, Training loss 0.8608, Validation loss 0.8967\n",
      "Epoch 2100, Training loss 0.8581, Validation loss 0.8941\n",
      "Epoch 2200, Training loss 0.8556, Validation loss 0.8917\n",
      "Epoch 2300, Training loss 0.8532, Validation loss 0.8893\n",
      "Epoch 2400, Training loss 0.8509, Validation loss 0.8871\n",
      "Epoch 2500, Training loss 0.8487, Validation loss 0.8850\n",
      "Epoch 2600, Training loss 0.8466, Validation loss 0.8831\n",
      "Epoch 2700, Training loss 0.8446, Validation loss 0.8812\n",
      "Epoch 2800, Training loss 0.8427, Validation loss 0.8794\n",
      "Epoch 2900, Training loss 0.8410, Validation loss 0.8777\n",
      "Epoch 3000, Training loss 0.8393, Validation loss 0.8761\n"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 3000,\n",
    "    optimizer = optimizer,\n",
    "    model = seq_model,\n",
    "    loss_fn = loss_fn,\n",
    "    wine_train = wine_train,\n",
    "    wine_val = wine_val,\n",
    "    wine_target_train = wine_target_train,\n",
    "    wine_target_val = wine_target_val)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>a. 앞에서 다룬 온도 데이터와 비교할 때 훈련 시간이 얼마나 더 오래 걸리나? </h2>\n",
    "<h3> - 온도 데이터의 학습 시간은 초 단위였다. 하지만 와인 데이터는 학습에 4~5분 정도 소모됬다. 와인 데이터가 학습이 5분정도 더 오래 걸린다.</h3>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>b. 어떤 요소가 훈련 시간에 영향을 주는지 설명할 수 있는가? </h2>\n",
    "<h3> - 데이터 셋의 크기 차이가 가장 큰 영향을 준 것 같다. 배치 단위로 분할하여 넣었다면 시간이 조금 단축 됬을 것 같다. 또한 모델의 파라미터의 숫자가 많아 학습 시간에 차이가 크게 나타났다. 와인 데이터는 약 3000개의 학습 데이터와 약 1000개의 평가 데이터를 가진다. 이들을 256개의 출력을 가진 레이어를 통과하면 가중치의 수는 대략 76만개를 넘어간다. 이는 학습해야 하는 값이 많아 지고 학습 시간을 증가시킨다.</h3>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>c. 데이터셋으로 훈련시키는 동안 손실이 줄어들었는가? </h2>\n",
    "<h3> - 손실 값은 Train, Validation 값 모두 줄었다.</h3>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>d. 데이터셋을 어떻게 그래프로 표현할 것인가?</h2>\n",
    "<h3> - 와인 데이터의 입력값인 11개의 값별로 1개의 출력값인 품질 값이 나오도록 11개의 그래프를 그릴 수 있을 것 같다.</h3>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}